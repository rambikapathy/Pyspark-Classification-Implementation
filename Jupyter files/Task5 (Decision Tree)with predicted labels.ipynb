{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data (Task 5) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.stat import Correlation\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LinearSVC, MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"nuclear_plants_small_dataset.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType,BooleanType,DateType\n",
    "\n",
    "df= df.withColumn(\"Power_range_sensor_1\",df[\"Power_range_sensor_1\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Power_range_sensor_2\",df[\"Power_range_sensor_2\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Power_range_sensor_3 \",df[\"Power_range_sensor_3 \"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Power_range_sensor_4\",df[\"Power_range_sensor_4\"].cast(IntegerType()))\n",
    "\n",
    "df= df.withColumn(\"Pressure _sensor_1\",df[\"Pressure _sensor_1\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Pressure _sensor_2\",df[\"Pressure _sensor_2\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Pressure _sensor_3\",df[\"Pressure _sensor_3\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Pressure _sensor_4\",df[\"Pressure _sensor_4\"].cast(IntegerType()))\n",
    "\n",
    "df= df.withColumn(\"Vibration_sensor_1\",df[\"Vibration_sensor_1\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Vibration_sensor_2\",df[\"Vibration_sensor_2\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Vibration_sensor_3\",df[\"Vibration_sensor_3\"].cast(IntegerType()))\n",
    "df= df.withColumn(\"Vibration_sensor_4\",df[\"Vibration_sensor_4\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler= VectorAssembler(inputCols=['Power_range_sensor_1',\n",
    " 'Power_range_sensor_2',\n",
    " 'Power_range_sensor_3 ',\n",
    " 'Power_range_sensor_4',\n",
    " 'Pressure _sensor_1',\n",
    " 'Pressure _sensor_2',\n",
    " 'Pressure _sensor_3',\n",
    " 'Pressure _sensor_4',\n",
    " 'Vibration_sensor_1',\n",
    " 'Vibration_sensor_2',\n",
    " 'Vibration_sensor_3',\n",
    " 'Vibration_sensor_4'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer=StringIndexer(inputCol=\"Status\",outputCol=\"Status_ind\")\n",
    "indexed=indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix = indexed.select(\"features\", \"Status_ind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Status',\n",
       " 'Power_range_sensor_1',\n",
       " 'Power_range_sensor_2',\n",
       " 'Power_range_sensor_3 ',\n",
       " 'Power_range_sensor_4',\n",
       " 'Pressure _sensor_1',\n",
       " 'Pressure _sensor_2',\n",
       " 'Pressure _sensor_3',\n",
       " 'Pressure _sensor_4',\n",
       " 'Vibration_sensor_1',\n",
       " 'Vibration_sensor_2',\n",
       " 'Vibration_sensor_3',\n",
       " 'Vibration_sensor_4',\n",
       " 'features',\n",
       " 'Status_ind']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the dataset using randomSplit then split the dataset into 70% training and 30% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df,test_df=df_fix.randomSplit([0.7,0.3], seed=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Power_range_sensor_1: integer (nullable = true)\n",
      " |-- Power_range_sensor_2: integer (nullable = true)\n",
      " |-- Power_range_sensor_3 : integer (nullable = true)\n",
      " |-- Power_range_sensor_4: integer (nullable = true)\n",
      " |-- Pressure _sensor_1: integer (nullable = true)\n",
      " |-- Pressure _sensor_2: integer (nullable = true)\n",
      " |-- Pressure _sensor_3: integer (nullable = true)\n",
      " |-- Pressure _sensor_4: integer (nullable = true)\n",
      " |-- Vibration_sensor_1: integer (nullable = true)\n",
      " |-- Vibration_sensor_2: integer (nullable = true)\n",
      " |-- Vibration_sensor_3: integer (nullable = true)\n",
      " |-- Vibration_sensor_4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree classfier used to interpret categorical features.\n",
    "#It can break down dataset into smaller subsets while an associated tree is developed.\n",
    "df_classifier = DecisionTreeClassifier(labelCol=\"Status_ind\", featuresCol=\"features\").fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_classifier.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MullticlassClassificationEvaluator is used to classifies data into a specific class, in this case expects input index, prediction and accuracy for evaulating the prediction label\n",
    "df_accuracy = MulticlassClassificationEvaluator(labelCol=\"Status_ind\",predictionCol= \"prediction\",metricName=\"accuracy\").evaluate(df_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Status_ind: double (nullable = false)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "log_reg=LogisticRegression(labelCol=\"Status_ind\").fit(training_df)\n",
    "#LogisticRegression used to predict categorical response to help classification type machine learning problems.\n",
    "\n",
    "results=log_reg.evaluate(test_df).predictions\n",
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+----------+\n",
      "|features                                              |prediction|\n",
      "+------------------------------------------------------+----------+\n",
      "|[0.0,3.0,3.0,4.0,12.0,2.0,3.0,0.0,16.0,17.0,0.0,15.0] |0.0       |\n",
      "|[0.0,3.0,4.0,3.0,23.0,0.0,5.0,1.0,17.0,10.0,1.0,14.0] |0.0       |\n",
      "|[0.0,3.0,5.0,2.0,21.0,0.0,5.0,1.0,20.0,13.0,6.0,6.0]  |0.0       |\n",
      "|[0.0,4.0,5.0,2.0,15.0,2.0,3.0,0.0,30.0,12.0,8.0,16.0] |0.0       |\n",
      "|[0.0,4.0,6.0,7.0,42.0,0.0,2.0,0.0,5.0,5.0,4.0,7.0]    |0.0       |\n",
      "|[0.0,4.0,6.0,8.0,36.0,0.0,3.0,3.0,13.0,8.0,12.0,2.0]  |0.0       |\n",
      "|[0.0,4.0,8.0,4.0,6.0,2.0,5.0,0.0,9.0,9.0,11.0,6.0]    |0.0       |\n",
      "|[0.0,4.0,8.0,4.0,8.0,2.0,4.0,0.0,7.0,5.0,13.0,11.0]   |0.0       |\n",
      "|[0.0,5.0,5.0,3.0,14.0,0.0,6.0,0.0,27.0,22.0,6.0,3.0]  |0.0       |\n",
      "|[0.0,5.0,7.0,2.0,17.0,0.0,8.0,0.0,13.0,27.0,4.0,2.0]  |0.0       |\n",
      "|[0.0,5.0,7.0,7.0,21.0,1.0,2.0,3.0,11.0,18.0,20.0,6.0] |0.0       |\n",
      "|[0.0,5.0,8.0,1.0,14.0,0.0,8.0,1.0,11.0,23.0,2.0,9.0]  |0.0       |\n",
      "|[0.0,6.0,8.0,2.0,15.0,1.0,7.0,1.0,8.0,27.0,5.0,12.0]  |0.0       |\n",
      "|[0.0,8.0,11.0,0.0,23.0,2.0,8.0,1.0,17.0,5.0,8.0,8.0]  |0.0       |\n",
      "|[0.0,9.0,9.0,0.0,1.0,1.0,7.0,0.0,8.0,20.0,1.0,2.0]    |0.0       |\n",
      "|[0.0,9.0,10.0,0.0,4.0,0.0,10.0,1.0,0.0,4.0,11.0,9.0]  |0.0       |\n",
      "|[0.0,10.0,10.0,7.0,6.0,1.0,6.0,0.0,16.0,7.0,33.0,16.0]|1.0       |\n",
      "|[1.0,0.0,5.0,2.0,28.0,0.0,2.0,5.0,11.0,1.0,3.0,2.0]   |0.0       |\n",
      "|[1.0,1.0,6.0,1.0,1.0,0.0,5.0,6.0,18.0,4.0,5.0,0.0]    |0.0       |\n",
      "|[1.0,1.0,6.0,2.0,22.0,0.0,4.0,4.0,2.0,21.0,5.0,21.0]  |0.0       |\n",
      "+------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select([\"features\",\"prediction\"]).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = MulticlassClassificationEvaluator(labelCol=\"Status_ind\",predictionCol= \"prediction\",metricName=\"accuracy\").evaluate(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.83870967741936"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = 100 - df_accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.16129032258064"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "tp = results[(results.Status_ind== 1) & (results.prediction== 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = results[(results.Status_ind == 0) & (results.prediction ==0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = results[(results.Status_ind == 0) & (results.prediction == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = results[(results.Status_ind == 1) & (results.prediction ==0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy=float((tp+tn)/(results.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.06451612903226"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "recall = float(tn)/(tp + tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Error rate  (`Incorrectly Classified Samples’ divided by Classified Sample’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate (FP + FN) /(p+n) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n"
     ]
    }
   ],
   "source": [
    "# total rows in test dataset\n",
    "totaltestrows = df.count()\n",
    "print(totaltestrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate total positives from dataset\n",
    "positive = fp + tp\n",
    "\n",
    "#Calculate total negatives from dataset\n",
    "negative = fn + tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = positive + negative\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalFalse = fp + fn\n",
    "totalFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.93548387096774"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Errorrate = totalFalse / total\n",
    "Errorrate*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity (tn/n)  <br>\n",
    "\n",
    "Specificity (SP) is calculated as the number of correct negative predictions divided by the total number of negatives. It is also called true negative rate (TNR). The best specificity is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity = tn / negative\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity (tp/p)  <br>\n",
    "\n",
    "Sensitivity (Recall or True positive rate)\n",
    "Sensitivity (SN) is calculated as the number of correct positive predictions divided by the total number of positives. It is also called recall (REC) or true positive rate (TPR). The best sensitivity is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6733333333333333"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = tp / positive\n",
    "sensitivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
